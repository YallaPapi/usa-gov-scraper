# Data Guidance and Provenance

This repository contains a mix of reproducible outputs (generated by the current code) and legacy, experimental, or non‑authoritative artifacts. Use this guide to understand what is safe for production and what is for reference/testing only.

## Authoritative Outputs

- `scraped_data/usa_gov_agencies_*.csv/json`
  - Produced by the core scraper (`scraper/core.py`) or the Botasaurus variant (`scraper/botasaurus_core.py`).
  - Use `data_cleanup.py` to sanitize before downstream use.

- `government_contacts.db`
  - SQLite DB initialized by `scripts/db_init.py` and populated via `scripts/load_from_csv.py`.
  - Serves as the backing store for the REST API.

## Non‑Authoritative or Experimental

Treat the following as examples or experiments unless you have verified provenance:

- `output_clean/` (pre‑cleaned examples)
- `operation_intelligence_exports/`
- `discovery/` (mass domain generation artifacts)
- `database_exports*/` (exports not clearly linked to a reproducible pipeline here)

These may contain synthetic data, placeholder values, or results from earlier iterations. Do not use them as a source of truth.

## Recommended Pipeline

1. Scrape (Simple mode)
   - `python main.py --simple --log-level INFO`
2. Clean
   - `python data_cleanup.py --input-dir scraped_data --output-dir output_clean`
3. Initialize DB
   - `python scripts/db_init.py --db government_contacts.db`
4. Load Data
   - `python scripts/load_from_csv.py --db government_contacts.db --agencies output_clean/usa_gov_agencies_*.csv`
5. Run API
   - Set `GOV_CONTACTS_DB_PATH` to the DB path
   - `python src/api/government_contacts_api.py`

## Notes

- The core scraper avoids internal `usa.gov` links and letter headers. Data still benefits from a cleaning pass.
- Orchestrated/agent‑based components are optional and not required for the pipeline above.

